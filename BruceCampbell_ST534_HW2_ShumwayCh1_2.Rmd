---
title: "Bruce Campell NCSU ST 534 Exam 1"
date: "`r format(Sys.time(), '%d %B, %Y')`"
fontsize: 12pt
header-includes:
   - \usepackage{bbm}
output: pdf_document
---

---
```{r setup, include=FALSE,echo=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(dev = 'pdf')
knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(tidy=TRUE)
knitr::opts_chunk$set(prompt=FALSE)
knitr::opts_chunk$set(fig.height=5)
knitr::opts_chunk$set(fig.width=7)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_knit$set(root.dir = ".")
library(latex2exp)   
library(pander)
library(ggplot2)
library(ggplot2)
library(GGally)
```

#1 
Generate a time series x of length 500 using the following R commands:

```{r}
t<-seq(1:500)
x<-cos(2* pi* .2 *t)+ (1-t/250)^3+rnorm(500)
x<-ts(x)
x.no.noise <- cos(2* pi* .2 *t)+ (1-t/250)^3
```

##(a) Plot x. Does the plot appear to be stationary?

```{r,echo=FALSE}
plot(x)
sm <-mean(x)
plot(x, main = "time series along with sample mean and underlying noisless series")
plot(x)
points(t,x.no.noise,col='blue',pch='*')
abline(h=sm, col='red')
legend("topright", title.col = "black",c("time series","no noise term","sample mean" ), text.col =c("black","blue","red"))
```

This time series does not appear stationary, The mean function apperears to have drift and the variance does not appear constant. 

##(b) Plot the ACF of x. What feature(s) do(es) the acf-plot reveal ? 

```{r echo=FALSE}
acf(x)
```

We see negative autocorrelation at lags 2,3  and lags $l_i : l_i \ni  2 mod 5 =0,l_i \ni  3 mod 5 =0FIX$.
We see positive autocorrelation at lags 4,5,6 with the strongest peak at lag 5. 


##(c) Plot x and overlay two kernel smoothed curves using the Gaussian ("normal")
kernel with two different choices of the bandwidth b = 30; 50. 

```{r, echo=FALSE}
plot(x)
lines(ksmooth(time(x),x, "normal", bandwidth = 30), col='red')
lines(ksmooth(time(x),x, "normal", bandwidth = 50), col='blue')
#lines(ksmooth(time(x),x, "normal", bandwidth = 1/.2), col='cyan')
```

(d) Which of the two smoothed curves (or the bandwidths) gives a better description
of the "trend function" $g(t) = (1-\frac{t}{250})$ ? Justify your answer by relating the
bandwidth choice with the period of the cyclical component.

The kernel with the larger bandwidth will capture the trend better. 


#2 Consider the time series varve given in the package ASTSA.
(a) Show that the varve series is heteroscedastic by computing the sample variances
over the first and the second half of the data. 

```{r}
rm(list = ls())
library(astsa)
data(varve, package="astsa")
plot(ts(varve))
n.tics <- length(varve)

left.half <- window(varve,start = 1,end = floor(length(varve) /2))
right.half <- window (varve,start=floor(length(varve) /2) +1, end = length(varve))

mean.left <- mean(left.half)
mean.right <- mean(right.half)
pander(data.frame(mean.left = mean.left, mean.right = mean.right), caption = "Sample means for right and left half of varve ts")

var.left <- var(left.half)
var.right <- var(right.half)

pander(data.frame(var.left = var.left, var.right = var.right), caption = "Sample variances for right and left half of varve ts")
```

(b) Let x1 denote the first half of the varve series scaled by the sample standard
deviation of the first half, and similarly, let x2 denote the second half of the
varve series scaled by the sample standard deviation of the second half. Plot the
two subseries x1 and x2 in two panels using the plotting function mfrow=c(2,1).

```{r}
x1 <- left.half
x2 <- right.half
x1.scaled<- scale(left.half,center = FALSE,scale = sqrt(var.left))
x2.scaled<- scale(right.half,center = FALSE, scale = sqrt(var.right))

par(mfrow=c(2,1), mar=c(3,2,1,0)+.5, mgp=c(1.6,.6,0))
plot(ts(x1.scaled),ylab="x1")
plot(ts(x2.scaled),ylab="x2")

```

(c) Now combine the two scaled series $x1$ and $x2$, and call it $xt$. Plot the ACF of the $xt$ series and comment on its (non-)stationarity properties! 

```{r}

union.x <- ts(union(x1.scaled,x2.scaled))
plot(union.x)
acf(union.x)
```

Since the acf is slowly decaying - we have evidence of non-stationarity. We can't say for sure though, but we should definitely investigate for trend.  If we were taking the follow up course - we'd be curous about unit root test - I believe these are for detecting long range correlations in time series.

###Experiments 

```{r}
fit = lm(union.x~time(union.x), na.action=NULL) 
par(mfrow=c(2,1))
plot(resid(fit), type="o", main="detrended")
plot(diff(union.x), type="o", main="first difference")
par(mfrow=c(3,1)) #plot ACFs
acf(union.x, 48, main="Union Scaled") 
acf(resid(fit), 48, main="detrended") 
acf(diff(union.x), 48, main="first difference")
```


(d) Consider the dfferenced time series $xdiff$ obtained from $xt$. Show that an $MA(1)$ model is appropriate for $xdiff$. 

```{r}
diff.union.x <- diff(union.x)
plot(diff.union.x, type="o", main="first difference")
acf(diff(union.x), 48, main="first difference")
```


We see in autocorrelation plot of the differenced data with a 95% confidence bands that the autocorrelation at lag 1 is significant.  Based on this a MA(1) model is suggested.  If we wanted to we could investigate the PACF to look for an AR component.  

There are two other significant ACF values at lag 9 and 10. They are of differneing sign, and they are not that far ablove the $\alpha=0.05$ line so we claim there is no need to include them in our modelling process at this point. 


(e) The model for $X_t = xdiff$ can be written as 
$$X_t = \mu + W_t + \theta_1 W_{t-1}$$ 
Where ${W_t} \sim N(-,\sigma_W)$.  Find an estimate of $\mu$.

We can fit a linear model $\mu_t = \beta_0 + \beta_1 t$ and see the trend in the original series.

```{r}
fit = lm(union.x~time(union.x), na.action=NULL) 
summary(fit)
mean(union.x)
plot(union.x)
lines(fitted(fit), col='red')
```

We know that we can also model trend as a random walk with drift $\mu_t = \delta+\mu_{t-1}+w_t$ for the differenced series we should have $\delta=0$
Let's see what happens when we fit a linear model to the differenced series $xdiff$

```{r}
fit.diff = lm(diff.union.x~time(diff.union.x), na.action=NULL) 
summary(fit.diff)
mean(diff.union.x)
plot(diff.union.x)
lines(fitted(fit.diff), col='red')
```
Indeed both the intercept and slope are not significant. 

Since $E[W_t] = 0 \;\;\forall t$ We have that $E[X_t]=\mu$ and it stands to reason that $\hat{\mu}=\bar{x_t}$ is a good estimate of $\mu$

```{r}
pander(data.frame(mean.xdiff=mean(diff.union.x)),capiton = "Estimate of constant in MA model")
```


(f) Write down the final model for the varve-series based on this analysis.


We can use the autocovariance function


# 3 
Suppose that $X_t$ is an $ARMA(p,q)$ process:
$$X_t = .5 X_{t-1} + W_t -0.7 W_{t-1} + 0.1 W_{t-1}$$
where $W_t$ are IID $N(0,1)$.
(a) Find $p$ and $q$. (Be sure to check for model redundancy.)
(b) Show that $X_t$ is invertible.
(c) Find the ACF of ${X_t}$ explicitly.
























